---
title: "PSI_Capstone Pair Project"
author: "Ruei Li Jhang & Chia Hua Lin"
date: "2024-03-25"
output: 
  html_document:
    toc: yes
    toc_depth: 5
    number_sections: yes
    theme: united
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
```


```{r message=FALSE, warning=FALSE}

# Loading libraries

library(dplyr)
library(ggplot2)
library(ltm)
library(randomForest)
library(rpart)


```



# Data Understanding

The data set was downloaded from Kaggle.com. According to the data description, the data focuses on malicious URL detection. This data helps in the development of cyber security systems that can detect any malicious attempt to gain access and send a sigal to systems to perform the relevant in return.

Data set link: https://www.kaggle.com/datasets/pilarpieiro/tabular-dataset-ready-for-malicious-url-detection/data

The data set includes URLs and 60 other calculated features. In our analysis, we will not use all the 60 features, but we will select the most important features. In the data description, a list of 9 important features has been provided and they are as follows:

* Basic URL Components

* Domain Information

* Content Analysis

* Host Reputation

* Network Features

* Behavioural Features



```{r}

# # Loading the train data
# train_data <- read.csv('train_dataset.csv')
# train_data <- na.omit(train_data) # Remove rows with any NA/null values
# dim(train_data)
 
# # Loading test data
# test_data <- read.csv('test_dataset.csv')
# test_data <- na.omit(test_data) # Remove rows with any NA/null values
# dim(test_data)

```

The original train data has 6,728,848 observations and the test data contains 1,682,213.


**Due to the computational resources, we will randomly select 200,000 observations for training and 100,000 observations for testing.** 



```{r}

# # Set seed for reproducibility
# set.seed(2024)

# # Define the number of samples you want for each label category
# num_samples_per_label <- 1000000

# # Sample from each label category
# train_data_sample <- train_data %>%
#    group_by(label) %>%
#    sample_n(num_samples_per_label, replace = TRUE)

# # Test data
# test_data_sample <- test_data[sample(nrow(test_data), 1000000), ]

# # Write train_data2 to CSV
# write.csv(train_data_sample, file = "train_data_sample.csv", row.names = FALSE)
# write.csv(test_data_sample, file = "test_data_sample.csv", row.names = FALSE)

```




## Loading the Save Data

```{r}

# Loading the train data
train_data <- read.csv('train_data_sample.csv')
train_data <- na.omit(train_data) # Remove rows with any NA/null values
dim(train_data)

# Loading the test data
test_data <- read.csv('test_data_sample.csv')
test_data <- na.omit(test_data) # Remove rows with any NA/null values
dim(test_data)

```




## Selecting Necessary Columns

We selected specific columns from the train_data data frame. The columns selected include various features related to URLs as:

* Whether the URL contains certain elements like login, client, server, admin, IP,
* Whether it is shortened,
* Its length, entropy,
* Its counts of various characters and components,
* Features related to the length
* Components of the path,
* Query, sub domain, and primary domain of the URL.
* Label column indicating some classification or labeling information associated with each URL.


```{r}

# Train data
train_data <- train_data %>%
  dplyr::select(url, source, url_has_login, url_has_client, url_has_server,
                url_has_admin, url_has_ip, url_isshorted, url_len, 
                url_entropy, url_count_dot, url_count_https, url_count_http,
                url_count_perc, url_count_hyphen, url_count_www,
                url_count_hash, url_count_semicolon, url_count_underscore, 
                url_count_ques, url_count_equal, url_count_amp,
                url_count_letter, url_count_digit,
                url_count_sensitive_financial_words, 
                url_count_sensitive_words, path_len, query_len, 
                query_count_components, pdomain_len, subdomain_len, 
                subdomain_count_dot, label
                )

```




## Exploratory Data Analysis

During EDA, we are going to perform tasks such as:

* Summarizing the distribution of each variable (count and distribution)
* Visualizing relationships between variables (scatter plots, box plots)
* Detecting outliers or anomalies (histograms)
* Exploring correlations between variables
* Identifying potential patterns or trends in the data


### Binary Variables

Here, we're preparing for Exploratory Data Analysis (EDA) by selecting specific columns from the train_data dataframe. We are identifying binary variables within the train_dataset. The criteria involve checking if the column is numeric and if it possesses only two unique values. If these conditions are satisfied, indicating that the column indeed contains binary data, we add it to the binary_vars list.


```{r}

# Initialize an empty list to store binary variables
binary_vars <- list()

# Loop through each column in the dataset
for (col in names(train_data)) {
  
  # Check if the column is numeric and has only two unique values
  if (is.numeric(train_data[[col]]) && length(unique(train_data[[col]])) == 2) {
    
    # If the condition is met, add the column to the list
    binary_vars[[col]] <- train_data[[col]]
  }
}

# Convert the list of binary variables to a dataframe
binary_df <- as.data.frame(binary_vars)

# Convert all columns in binary_df to factors
binary_df <- as.data.frame(lapply(binary_df, as.factor))

# Overview
head(binary_df, 5)

```




#### Distribution of url_has_login

```{r}

# Plotting the count of url_has_login
ggplot(binary_df, aes(x = url_has_login, fill = url_has_login)) +
  geom_bar(stat = "count", position = "dodge") +
  geom_text(stat = "count", aes(label = after_stat(count)),
            vjust = -0.2, position = position_dodge(width = 0.8)) +
  labs(title = "Distribution of url_has_login",
       x = "url_has_login",
       y = "Count") +
  theme_minimal() +
  facet_wrap(~ label, labeller = labeller(label = c("0" = "benign", "1" = "Malicious")))

```

For the URLs that are no malicious, 99986 had no log in while 14 had log in. For the malicious URLs, 92849 had no log in while 7151 had log in.




#### Distribution of url_has_client

```{r}

ggplot(binary_df, aes(x = url_has_client, fill = url_has_client)) +
  geom_bar(stat = "count", position = "dodge") +
  geom_text(stat = "count", aes(label = after_stat(count)),
            vjust = -0.2, position = position_dodge(width = 0.8)) +
  labs(title = "Distribution of url_has_client",
       x = "url_has_client",
       y = "Count") +
  theme_minimal() +
  facet_wrap(~ label, labeller = labeller(label = c("0" = "benign", "1" = "Malicious")))

```

For the URLs that are no malicious, 99987 had no client in while 13 had client. For the malicious URLs, 99123 had no client in while 877 had client.




#### Distribution of url_has_server

```{r}

# Plotting the count of url_has_server
ggplot(binary_df, aes(x = url_has_server, fill = url_has_server)) +
  geom_bar(stat = "count", position = "dodge") +
  geom_text(stat = "count", aes(label = after_stat(count)),
            vjust = -0.2, position = position_dodge(width = 0.8)) +
  labs(title = "Distribution of url_has_server",
       x = "url_has_server",
       y = "Count" ) +
  theme_minimal() +
  facet_wrap(~ label, labeller = labeller(label = c ("0" = "benign", "1" = "Malicious")))

```

For the UELs that are not malicious, 99839 had no server in while 161 had server. For the malicious URLs, 99512 had no server in while 488 had server.




#### Distribution of url_has_admin

```{r}

#plotting the count of url_has_admin
ggplot(binary_df, aes(x = url_has_admin, fill = url_has_admin)) +
  geom_bar(stat = "count", position = "dodge") +
  geom_text(stat = "count", aes(label = after_stat(count)),
            vjust = -0.2, position = position_dodge(width = 0.8)) +
  labs(title = "Distribution of url_has_admin",
       x = "url_has_admin",
       y = "Count" ) +
  theme_minimal() +
  facet_wrap(~ label, labeller = labeller(label = c("0" = "benign", "1" = "Milicious")))

```

For the URLs that are not malicious, 99950 had no admin in while 50 had admin. For the malicious URLs, 98442 had no admin while 1558 had admin.




#### Distribution of url_has_ip

```{r}

# Plotting the count of url_has_ip
ggplot(binary_df, aes(x = url_has_ip, fill = url_has_ip)) +
  geom_bar(stat = "count", position = "dodge") +
  geom_text(stat = "count", aes(label = after_stat(count)), 
            vjust = -0.2, position = position_dodge(width = 0.8)) +
  labs(title = "Distribution of url_has_ip",
       x = "url_has_ip",
       y = "Count" ) +
  theme_minimal() +
  facet_wrap(~ label, labeller = labeller(label = c("0" = "benign", "1" = "Malicious")))

```

For the URLs that are not malicious, all had no IP. For the malicious URLs, 98374 had no IP in while 1626 had IP.




#### Distribution of url_isshorted

```{r}

# Plotting the count of url_isshorted
ggplot(binary_df, aes(x = url_isshorted, fill = url_isshorted)) +
  geom_bar(stat = "count", position = "dodge") +
  geom_text(stat = "count", aes(label = after_stat(count)),
            vjust = -0.2, position = position_dodge(width = 0.8)) +
  labs(title = "Distribution of url_isshorted",
       x = "url_isshorted",
       y = "Count" ) +
  theme_minimal() +
  facet_wrap(~ label, labeller = labeller(label = c("0" = "benign", "1" = "Milicious")))

```

For the URLs that are no milicious, 4475 were shortened in while 95525 were not. For the malicious URLs, 7091 were shortened in while 92909 were not.





#### Distribution of Label

```{r}

# Plotting the count of label
ggplot(binary_df, aes(x = label, fill = label)) +
  geom_bar(stat = "count", position = "dodge") +
  geom_text(stat = "count", aes(label = after_stat(count)),
            vjust = -0.2, position = position_dodge(width = 0.8)) +
  labs(title = "Distribution of label",
       x = "label",
       y = "Count" ) +
  theme_minimal()

```

Out target variable which is Label, is was balanced.




### Distribution of Numerical Variables

```{r}

# Selecting all columns except the ones mentioned in binary
numerical_columns <- train_data[, !names(train_data) %in% names(binary_df)]

# Remove the first two columns
numerical_columns <- numerical_columns %>%
  dplyr::select(-url, -source)

```

